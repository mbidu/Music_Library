{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1678,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jupyter nbconvert --to python Extract_Playlist_With_Duplicates.ipynb\n",
    "\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import csv\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1679,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Making CSV...\n"
     ]
    }
   ],
   "source": [
    "print(\"...Making CSV...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1680,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Authentication - without user\n",
    "with open(r\"C:\\Users\\mackt\\Python\\Music Library\\Spotify_App_Credentials.txt\") as f:\n",
    "    sac_lines = f.readlines()\n",
    "    cid = sac_lines[0].split(\", \")\n",
    "    cid = cid[1].split(\"\\n\")\n",
    "    cid = cid[0]\n",
    "    # print(cid)\n",
    "    secret = sac_lines[1].split(\", \")\n",
    "    secret = secret[1]\n",
    "    # print(secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1681,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_credentials_manager = SpotifyClientCredentials(client_id=cid, client_secret=secret)\n",
    "sp = spotipy.Spotify(client_credentials_manager = client_credentials_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1682,
   "metadata": {},
   "outputs": [],
   "source": [
    "# playlist_link = \"https://open.spotify.com/playlist/5F5yHyXHt6vp2taA7DrEhJ?si=b4f82e9651444f28\"\n",
    "playlist_link = \"https://open.spotify.com/playlist/7LaicnuGlBjUoHZ5Rd4tjm?si=e9f47ebd992b4d08\"\n",
    "playlist_URI = playlist_link.split(\"/\")[-1].split(\"?\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1683,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = sp.playlist_tracks(playlist_URI)\n",
    "tracks = results['items']\n",
    "while results['next']:\n",
    "    results = sp.next(results)\n",
    "    tracks.extend(results['items'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1684,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'danceability': 0.73, 'energy': 0.777, 'key': 3, 'loudness': -5.199, 'mode': 0, 'speechiness': 0.0479, 'acousticness': 0.108, 'instrumentalness': 0.000467, 'liveness': 0.069, 'valence': 0.591, 'tempo': 130.0, 'type': 'audio_features', 'id': '20zQZVyUNPbq8kZACdgYrh', 'uri': 'spotify:track:20zQZVyUNPbq8kZACdgYrh', 'track_href': 'https://api.spotify.com/v1/tracks/20zQZVyUNPbq8kZACdgYrh', 'analysis_url': 'https://api.spotify.com/v1/audio-analysis/20zQZVyUNPbq8kZACdgYrh', 'duration_ms': 284867, 'time_signature': 4}] \n",
      "\n",
      "{'album': {'album_type': 'album', 'artists': [{'external_urls': {'spotify': 'https://open.spotify.com/artist/2DlGxzQSjYe5N6G9nkYghR'}, 'href': 'https://api.spotify.com/v1/artists/2DlGxzQSjYe5N6G9nkYghR', 'id': '2DlGxzQSjYe5N6G9nkYghR', 'name': 'Jennifer Lopez', 'type': 'artist', 'uri': 'spotify:artist:2DlGxzQSjYe5N6G9nkYghR'}], 'available_markets': ['CA', 'MX', 'US'], 'external_urls': {'spotify': 'https://open.spotify.com/album/1RJ3ZqXAzt0rsJhs80AqRb'}, 'href': 'https://api.spotify.com/v1/albums/1RJ3ZqXAzt0rsJhs80AqRb', 'id': '1RJ3ZqXAzt0rsJhs80AqRb', 'images': [{'height': 640, 'url': 'https://i.scdn.co/image/ab67616d0000b273ac888ad505c39f50656eac16', 'width': 640}, {'height': 300, 'url': 'https://i.scdn.co/image/ab67616d00001e02ac888ad505c39f50656eac16', 'width': 300}, {'height': 64, 'url': 'https://i.scdn.co/image/ab67616d00004851ac888ad505c39f50656eac16', 'width': 64}], 'name': 'LOVE?', 'release_date': '2011-01-01', 'release_date_precision': 'day', 'total_tracks': 12, 'type': 'album', 'uri': 'spotify:album:1RJ3ZqXAzt0rsJhs80AqRb'}, 'artists': [{'external_urls': {'spotify': 'https://open.spotify.com/artist/2DlGxzQSjYe5N6G9nkYghR'}, 'href': 'https://api.spotify.com/v1/artists/2DlGxzQSjYe5N6G9nkYghR', 'id': '2DlGxzQSjYe5N6G9nkYghR', 'name': 'Jennifer Lopez', 'type': 'artist', 'uri': 'spotify:artist:2DlGxzQSjYe5N6G9nkYghR'}, {'external_urls': {'spotify': 'https://open.spotify.com/artist/0TnOYISbd1XYRBk9myaseg'}, 'href': 'https://api.spotify.com/v1/artists/0TnOYISbd1XYRBk9myaseg', 'id': '0TnOYISbd1XYRBk9myaseg', 'name': 'Pitbull', 'type': 'artist', 'uri': 'spotify:artist:0TnOYISbd1XYRBk9myaseg'}], 'available_markets': ['CA', 'MX', 'US'], 'disc_number': 1, 'duration_ms': 284866, 'explicit': False, 'external_ids': {'isrc': 'USUM71104034'}, 'external_urls': {'spotify': 'https://open.spotify.com/track/20zQZVyUNPbq8kZACdgYrh'}, 'href': 'https://api.spotify.com/v1/tracks/20zQZVyUNPbq8kZACdgYrh', 'id': '20zQZVyUNPbq8kZACdgYrh', 'is_local': False, 'name': 'On The Floor', 'popularity': 63, 'preview_url': None, 'track_number': 1, 'type': 'track', 'uri': 'spotify:track:20zQZVyUNPbq8kZACdgYrh'} \n",
      "\n",
      "2DlGxzQSjYe5N6G9nkYghR \n",
      "\n",
      "['dance pop', 'pop', 'pop rap', 'urban contemporary'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for track in tracks:\n",
    "    # print(track[\"track\"][\"name\"])\n",
    "    pass\n",
    "# print(sp.audio_analysis(track[\"track\"][\"id\"]), '\\n')\n",
    "print(sp.audio_features(track[\"track\"][\"uri\"]), '\\n')\n",
    "print(sp.track(track[\"track\"][\"uri\"]), '\\n')\n",
    "print(track[\"track\"][\"artists\"][0][\"id\"], '\\n')\n",
    "print(sp.artist(track[\"track\"][\"artists\"][0][\"id\"])[\"genres\"], '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1685,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Downfall of Us All\n",
      "The Downfall Of Us All\n",
      "Adam's Song\n",
      "Adam's Song\n",
      "Adam's Song\n",
      "Alive\n",
      "Alive\n",
      "Alive\n",
      "Alive\n",
      "Alive\n",
      "On The Floor\n",
      "{'dup_id': 0, 'num_dup': 1, 'dup_loc0': 0, 'dup_loc1': 1}\n",
      "{'dup_id': 0, 'num_dup': 1, 'dup_loc0': 0, 'dup_loc1': 1}\n",
      "{'dup_id': 2, 'num_dup': 2, 'dup_loc0': 2, 'dup_loc1': 3, 'dup_loc2': 4}\n",
      "{'dup_id': 2, 'num_dup': 2, 'dup_loc0': 2, 'dup_loc1': 3, 'dup_loc2': 4}\n",
      "{'dup_id': 2, 'num_dup': 2, 'dup_loc0': 2, 'dup_loc1': 3, 'dup_loc2': 4}\n",
      "{'dup_id': 5, 'num_dup': 2, 'dup_loc0': 5, 'dup_loc1': 7, 'dup_loc2': 9}\n",
      "{'dup_id': 6, 'num_dup': 1, 'dup_loc0': 6, 'dup_loc1': 8}\n",
      "{'dup_id': 5, 'num_dup': 2, 'dup_loc0': 5, 'dup_loc1': 7, 'dup_loc2': 9}\n",
      "{'dup_id': 6, 'num_dup': 1, 'dup_loc0': 6, 'dup_loc1': 8}\n",
      "{'dup_id': 5, 'num_dup': 2, 'dup_loc0': 5, 'dup_loc1': 7, 'dup_loc2': 9}\n",
      "{'dup_id': -1, 'num_dup': 0}\n"
     ]
    }
   ],
   "source": [
    "# Song Library\n",
    "\n",
    "sl_tr_id = []\n",
    "\n",
    "\n",
    "\n",
    "sl_tr_uri1 = []\n",
    "sl_tr_uri2 = []\n",
    "sl_tr_uri3 = []\n",
    "sl_tr_uri4 = []\n",
    "sl_tr_uri5 = []\n",
    "\n",
    "Duplicate_Index = []\n",
    "Duplicate_ID = []\n",
    "\n",
    "sl_tr_name = []\n",
    "sl_tr_name_LOW = []\n",
    "# All uris for each song\n",
    "sl_tr_uri = []\n",
    "\n",
    "# All Artists for each song\n",
    "sl_ar_name = []\n",
    "sl_ar_uri = []\n",
    "\n",
    "lib = {}\n",
    "l = 0\n",
    "track_id = 1\n",
    "\n",
    "for track in tracks:\n",
    "    lib[\"track{0}\". format(l)] = {}\n",
    "\n",
    "    # Track Name and URI\n",
    "    lib[\"track{0}\". format(l)][\"id\"] = l\n",
    "\n",
    "    # Track Name and URI\n",
    "    track_uri = track[\"track\"][\"uri\"]\n",
    "    track_name = track[\"track\"][\"name\"]\n",
    "\n",
    "    lib[\"track{0}\". format(l)][\"uri\"] = track_uri\n",
    "    lib[\"track{0}\". format(l)][\"name\"] = track_name\n",
    "    lib[\"track{0}\". format(l)][\"name_low\"] = track_name.lower()\n",
    "\n",
    "    sl_tr_name.append(track_name)\n",
    "    sl_tr_name_LOW.append(track_name.lower())\n",
    "    sl_tr_uri.append(track_uri)\n",
    "\n",
    "    # Artists Name and URI\n",
    "    track_artists_name = []\n",
    "    track_artists_uri = []\n",
    "\n",
    "    lib[\"track{0}\". format(l)][\"artists\"] = {}\n",
    "    for i in range (10):\n",
    "        lib[\"track{0}\". format(l)][\"artists\"][\"ar_name{0}\". format(i)] = track[\"track\"][\"artists\"][i][\"name\"]\n",
    "        lib[\"track{0}\". format(l)][\"artists\"][\"ar_uri{0}\". format(i)] = track[\"track\"][\"artists\"][i][\"uri\"]\n",
    "\n",
    "        track_artists_name.append(track[\"track\"][\"artists\"][i][\"name\"])\n",
    "        track_artists_uri.append(track[\"track\"][\"artists\"][i][\"uri\"])\n",
    "\n",
    "        i = i + 1\n",
    "        try: track[\"track\"][\"artists\"][i][\"name\"]\n",
    "        except IndexError:\n",
    "            y = i-1\n",
    "            sl_ar_name.append(track_artists_name)\n",
    "            sl_ar_uri.append(track_artists_uri)\n",
    "            break\n",
    "\n",
    "    # Track Release Date + Local\n",
    "    # Local Tracks\n",
    "    if track['is_local'] == True:\n",
    "        lib[\"track{0}\". format(l)][\"date_spot\"] = 'None'\n",
    "        lib[\"track{0}\". format(l)][\"local\"] = 'Yes'\n",
    "    # Spotify Tracks\n",
    "    else:\n",
    "        track_release_date = sp.track(track_uri)[\"album\"][\"release_date\"]\n",
    "        if sp.track(track_uri)[\"album\"][\"release_date_precision\"] == 'day':\n",
    "            track_release_date = datetime.strptime(track_release_date, \"%Y-%m-%d\").date()\n",
    "        elif sp.track(track_uri)[\"album\"][\"release_date_precision\"] == 'month':\n",
    "            track_release_date = datetime.strptime(track_release_date, \"%Y-%m\").date()\n",
    "        elif sp.track(track_uri)[\"album\"][\"release_date_precision\"] == 'year':\n",
    "            track_release_date = datetime.strptime(track_release_date, \"%Y\").date()\n",
    "        lib[\"track{0}\". format(l)][\"date_spot\"] = track_release_date\n",
    "        lib[\"track{0}\". format(l)][\"local\"] = 'No'\n",
    "\n",
    "    # Track Duration\n",
    "    feature_aud = sp.audio_features(track_uri)[0]\n",
    "\n",
    "    if track['is_local'] == True:\n",
    "        lib[\"track{0}\". format(l)][\"time\"] = track[\"track\"][\"duration_ms\"]\n",
    "    else:\n",
    "        lib[\"track{0}\". format(l)][\"time\"] = feature_aud[\"duration_ms\"]\n",
    "\n",
    "    # Track Album\n",
    "    lib[\"track{0}\". format(l)][\"album\"] = track[\"track\"][\"album\"][\"name\"]\n",
    "\n",
    "    # Track Popularity\n",
    "    lib[\"track{0}\". format(l)][\"popularity\"] = track[\"track\"][\"popularity\"]\n",
    "\n",
    "    # Track Audio Features\n",
    "    # Locals\n",
    "    if track['is_local'] == True:\n",
    "        lib[\"track{0}\". format(l)][\"danceability\"] = 'None'\n",
    "        lib[\"track{0}\". format(l)][\"energy\"] = 'None'\n",
    "        lib[\"track{0}\". format(l)][\"key\"] = 'None'\n",
    "        lib[\"track{0}\". format(l)][\"loudness\"] = 'None'\n",
    "        lib[\"track{0}\". format(l)][\"mode\"] = 'None'\n",
    "        lib[\"track{0}\". format(l)][\"speechiness\"] = 'None'\n",
    "        lib[\"track{0}\". format(l)][\"acousticness\"] = 'None'\n",
    "        lib[\"track{0}\". format(l)][\"instrumentalness\"] = 'None'\n",
    "        lib[\"track{0}\". format(l)][\"liveness\"] = 'None'\n",
    "        lib[\"track{0}\". format(l)][\"valence\"] = 'None'\n",
    "        lib[\"track{0}\". format(l)][\"tempo\"] = 'None'\n",
    "    # Spotify\n",
    "    else:\n",
    "        lib[\"track{0}\". format(l)][\"danceability\"] = feature_aud[\"danceability\"]\n",
    "        lib[\"track{0}\". format(l)][\"energy\"] = feature_aud[\"energy\"]\n",
    "        lib[\"track{0}\". format(l)][\"key\"] = feature_aud[\"key\"]\n",
    "        lib[\"track{0}\". format(l)][\"loudness\"] = feature_aud[\"loudness\"]\n",
    "        lib[\"track{0}\". format(l)][\"mode\"] = feature_aud[\"mode\"]\n",
    "        lib[\"track{0}\". format(l)][\"speechiness\"] = feature_aud[\"speechiness\"]\n",
    "        lib[\"track{0}\". format(l)][\"acousticness\"] = feature_aud[\"acousticness\"]\n",
    "        lib[\"track{0}\". format(l)][\"instrumentalness\"] = feature_aud[\"instrumentalness\"]\n",
    "        lib[\"track{0}\". format(l)][\"liveness\"] = feature_aud[\"liveness\"]\n",
    "        lib[\"track{0}\". format(l)][\"valence\"] = feature_aud[\"valence\"]\n",
    "        lib[\"track{0}\". format(l)][\"tempo\"] = feature_aud[\"tempo\"]\n",
    "\n",
    "    # Duplicate Songs\n",
    "    lib[\"track{0}\". format(l)][\"duplicates\"] = {}\n",
    "    lib[\"track{0}\". format(l)][\"duplicates\"][\"dup_id\"] = -1\n",
    "    lib[\"track{0}\". format(l)][\"duplicates\"][\"num_dup\"] = 0\n",
    "\n",
    "    track_uris = [track_uri]\n",
    "    current_index = len(lib)\n",
    "\n",
    "    print(track_name)\n",
    "    same_tr_names = sl_tr_name_LOW.count(track_name.lower())-1\n",
    "    dup = 0\n",
    "    if same_tr_names != 0:\n",
    "        last_ind = 0\n",
    "        # print(same_tr_names, \"same name\")\n",
    "        for i in range(same_tr_names):\n",
    "            index = sl_tr_name_LOW.index(track_name.lower(), last_ind)\n",
    "            if sl_ar_uri[index] == track_artists_uri:\n",
    "                if dup == 0:\n",
    "                    dup = 1\n",
    "                    dup_id = index\n",
    "                    Duplicate_Index.append(dup_id)\n",
    "                    Duplicate_Index[index] = dup_id\n",
    "\n",
    "                    lib[\"track{0}\". format(l)][\"duplicates\"][\"num_dup\"] = dup\n",
    "                    lib[\"track{0}\". format(index)][\"duplicates\"][\"num_dup\"] = dup\n",
    "\n",
    "                    lib[\"track{0}\". format(l)][\"duplicates\"][\"dup_id\"] = dup_id\n",
    "                    lib[\"track{0}\". format(index)][\"duplicates\"][\"dup_id\"] = dup_id\n",
    "\n",
    "                    lib[\"track{0}\". format(index)][\"duplicates\"][\"dup_loc{0}\".format(dup-1)] = index\n",
    "\n",
    "                else:\n",
    "                    lib[\"track{0}\". format(l)][\"duplicates\"][\"num_dup\"] = dup\n",
    "\n",
    "                lib[\"track{0}\". format(l)][\"duplicates\"][\"dup_loc{0}\".format(dup-1)] = index\n",
    "                lib[\"track{0}\". format(l)][\"duplicates\"][\"dup_loc{0}\".format(dup)] = l\n",
    "\n",
    "                # iter = dup\n",
    "                # for x in range(dup):\n",
    "                #     prev_tr = lib[\"track{0}\". format(l)][\"duplicates\"][\"dup_loc{0}\".format(x)]\n",
    "                #     lib[\"track{0}\". format(prev_tr)][\"duplicates\"][\"num_dup\"] = dup\n",
    "                #     iter = iter - x\n",
    "\n",
    "                #     for y in range (iter):\n",
    "                #         a = lib[\"track{0}\". format(l)][\"duplicates\"][\"dup_loc{0}\".format(x+y+1)]\n",
    "                #         lib[\"track{0}\". format(prev_tr)][\"duplicates\"][\"dup_loc{0}\".format(x+y+1)] = a\n",
    "\n",
    "                dup = dup + 1\n",
    "                # print(index, \"+\")\n",
    "            elif i == same_tr_names-1 and dup == 0:\n",
    "                Duplicate_Index.append(-1)\n",
    "                # print(index, \"-\")\n",
    "\n",
    "            last_ind = index+1\n",
    "\n",
    "    else:\n",
    "        Duplicate_Index.append(-1)\n",
    "\n",
    "    dup = dup - 1\n",
    "    iter = dup\n",
    "    for x in range(dup):\n",
    "        prev_tr = lib[\"track{0}\". format(l)][\"duplicates\"][\"dup_loc{0}\".format(x)]\n",
    "        lib[\"track{0}\". format(prev_tr)][\"duplicates\"][\"num_dup\"] = dup\n",
    "        iter = iter - x\n",
    "\n",
    "        for y in range (iter):\n",
    "            a = lib[\"track{0}\". format(l)][\"duplicates\"][\"dup_loc{0}\".format(x+y+1)]\n",
    "            lib[\"track{0}\". format(prev_tr)][\"duplicates\"][\"dup_loc{0}\".format(x+y+1)] = a\n",
    "    # print(Duplicate_Index)\n",
    "\n",
    "    dup = lib[\"track{0}\". format(l)][\"duplicates\"][\"num_dup\"]\n",
    "\n",
    "    if dup >= 1:\n",
    "        for i in range(dup+1):\n",
    "            loc = lib[\"track{0}\". format(l)][\"duplicates\"][\"dup_loc{0}\".format(i)]\n",
    "            track_uri = lib[\"track{0}\". format(loc)][\"uri\"]\n",
    "            lib[\"track{0}\". format(l)][\"uri{0}\".format(i)] = track_uri\n",
    "    else:\n",
    "        lib[\"track{0}\". format(l)][\"uri0\"] = track_uri\n",
    "\n",
    "    l = l+1\n",
    "\n",
    "print(lib[\"track0\"][\"duplicates\"])\n",
    "print(lib[\"track1\"][\"duplicates\"])\n",
    "print(lib[\"track2\"][\"duplicates\"])\n",
    "print(lib[\"track3\"][\"duplicates\"])\n",
    "print(lib[\"track4\"][\"duplicates\"])\n",
    "print(lib[\"track5\"][\"duplicates\"])\n",
    "print(lib[\"track6\"][\"duplicates\"])\n",
    "print(lib[\"track7\"][\"duplicates\"])\n",
    "print(lib[\"track8\"][\"duplicates\"])\n",
    "print(lib[\"track9\"][\"duplicates\"])\n",
    "print(lib[\"track10\"][\"duplicates\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1686,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 2, 2, 2, 5, 6, 5, 6, 5, -1]\n",
      "[-1, 0, 2, 5, 6]\n",
      "[1, 2, 3, 3, 2]\n"
     ]
    }
   ],
   "source": [
    "# Number of [non-duplicate songs, duplicates of song 3, duplicates of song 5,...]\n",
    "# num_uniques [#nd, #song3, #song5...]\n",
    "num_uniques = []\n",
    "\n",
    "# Labeling uniques and duplicates\n",
    "# uniques = [-1, 1 , 2...]\n",
    "uniques = list(set(Duplicate_Index))\n",
    "uniques.sort()\n",
    "\n",
    "for i in range (len(uniques)):\n",
    "    count = Duplicate_Index.count(uniques[i])\n",
    "    num_uniques.append(count)\n",
    "\n",
    "print(Duplicate_Index)\n",
    "print(uniques)\n",
    "print(num_uniques)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1687,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(lib)\n",
    "df = pd.DataFrame.from_dict(lib, orient='index')\n",
    "df2 = df['artists'].apply(pd.Series)\n",
    "df3 = pd.concat([df.drop(['artists'], axis=1), df2], axis=1)\n",
    "\n",
    "\n",
    "df3.to_csv(r'C:\\Users\\mackt\\Python\\Music Library\\Data\\Playlist.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1688,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Artist 1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1688-35242535564e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Sort Alphabetically by Artist -> Album -> Song\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Artist 1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Album'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Song'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mascending\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Track IDs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msl_tr_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msl_tr_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36msort_values\u001b[1;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[0;32m   5440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5442\u001b[1;33m             \u001b[0mkeys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5443\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5444\u001b[0m             \u001b[1;31m# need to rewrap columns in Series to apply key function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   5440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5442\u001b[1;33m             \u001b[0mkeys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5443\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5444\u001b[0m             \u001b[1;31m# need to rewrap columns in Series to apply key function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1682\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1683\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1684\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1686\u001b[0m         \u001b[1;31m# Check for duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Artist 1'"
     ]
    }
   ],
   "source": [
    "# Sort Alphabetically by Artist -> Album -> Song\n",
    "df = df.sort_values(['Artist 1', 'Album', 'Song'], ascending = True, key = lambda col: col.str.lower())\n",
    "\n",
    "# Track IDs\n",
    "sl_tr_id = list(range(1,len(sl_tr_name)+1))\n",
    "df['ID'] = sl_tr_id\n",
    "\n",
    "# Creating CSV of Entire Playlist\n",
    "df.to_csv(r'C:\\Users\\mackt\\Python\\Music Library\\Data\\Playlist.csv',index = False)\n",
    "\n",
    "df = df.sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the dates of all duplicate songs to the earliest release date\n",
    "dup_date = {}\n",
    "\n",
    "for i in range(len(Duplicate_Index)):\n",
    "    if Duplicate_Index[i] != -1:\n",
    "        if Duplicate_Index[i] in dup_date:\n",
    "            if sl_tr_release[i] > dup_date[Duplicate_Index[i]]:\n",
    "                sl_tr_release[i] = dup_date[Duplicate_Index[i]]\n",
    "            else:\n",
    "                dup_date[Duplicate_Index[i]] = sl_tr_release[i]\n",
    "        else:\n",
    "            dup_date[Duplicate_Index[i]] = sl_tr_release[i]\n",
    "            dup_date[\"Loc{0}\".format(Duplicate_Index[i])] = i\n",
    "for i in range(len(Duplicate_Index)):\n",
    "    if Duplicate_Index[i] != -1:\n",
    "        sl_tr_release[i] = dup_date[Duplicate_Index[i]]\n",
    "    # print(sl_tr_release[i])\n",
    "\n",
    "df['Spot_Date'] = sl_tr_release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping Duplicates\n",
    "df = df.sort_values(['Popularity'], ascending = False)\n",
    "df = df.drop_duplicates(subset = ['song', 'Artist 1', 'Artist 2', 'Artist 3', 'Artist 4', 'Artist 5'], keep = 'first')\n",
    "df = df.sort_values(['Artist 1', 'Album', 'Song'], ascending = True, key = lambda col: col.str.lower())\n",
    "\n",
    "df.drop(['Duplicates', 'song'], axis=1, inplace=True)\n",
    "\n",
    "sl_tr_id = list(range(1,len(df)+1))\n",
    "df['ID'] = sl_tr_id\n",
    "\n",
    "# Creating CSV of Entire Playlist Without Duplicates\n",
    "df.to_csv(r'C:\\Users\\mackt\\Python\\Music Library\\Data\\Playlist_No_Duplicates.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "57baa5815c940fdaff4d14510622de9616cae602444507ba5d0b6727c008cbd6"
  },
  "kernelspec": {
   "display_name": "Python 3.7.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
